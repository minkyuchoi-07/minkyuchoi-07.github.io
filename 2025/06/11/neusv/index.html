<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification - Minkyu Choi&#39;s Personal Webpage</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="canonical" href="https://minkyuchoi-07.github.io/2025/06/11/neusv/">


    <meta name="description" content="Minkyu Choi*, S P Sharan*, Sahil Shah, Harsh Goel, Mohammad Omama, and Sandeep ChinchaliComputer Vision and Pattern Recognition (CVPR), 2025">
<meta property="og:type" content="article">
<meta property="og:title" content="Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification">
<meta property="og:url" content="https://minkyuchoi-07.github.io/2025/06/11/neusv/index.html">
<meta property="og:site_name" content="Minkyu Choi&#39;s Personal Webpage">
<meta property="og:description" content="Minkyu Choi*, S P Sharan*, Sahil Shah, Harsh Goel, Mohammad Omama, and Sandeep ChinchaliComputer Vision and Pattern Recognition (CVPR), 2025">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://minkyuchoi-07.github.io/img/me_main.jpg">
<meta property="article:published_time" content="2025-06-11T02:45:46.000Z">
<meta property="article:modified_time" content="2025-06-13T18:55:39.173Z">
<meta property="article:author" content="Minkyu Choi">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Neuro-symbolic AI">
<meta property="article:tag" content="Computer Vision">
<meta property="article:tag" content="Formal Method">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://minkyuchoi-07.github.io/img/me_main.jpg">




    <meta name="naver-site-verification" content="48beb5f578053c0c5f127b4198a57270bad360ca">


<link rel="canonical" href="https://minkyuchoi-07.github.io/2025/06/11/neusv/">


<link rel="alternative" href="/feed.xml" title="Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification" type="application/xml">



<link rel="icon" href="/img/favicon.png">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SNX6P4Y3TY"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-SNX6P4Y3TY');
</script>


    
    
    
    

    
    
    


<link rel="stylesheet" href="/css/style.css">


<script async src="https://www.googletagmanager.com/gtag/js?id=G-SNX6P4Y3TY"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-SNX6P4Y3TY');
</script>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9731816337848054", 
    enable_page_level_ads: true
  });
</script>

<meta name="generator" content="Hexo 5.4.2"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/" data-link-name="navigatorLogo">
            
                <img src="/img/logo.png" alt="Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a data-link-name="navigator" class="navbar-item" href="/">Home</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/1-research">Research</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/2-project">Project</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/3-blog-post">Blog</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/tags">Tags</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/cv">CV</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="GitHub" href="https://github.com/minkyu-choi07" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-10-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2025-06-11T02:45:46.000Z">2025-06-10</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/1-research/">1. Research</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-bold">
            
                Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification
            
        </h1>
        
        <hr>
        
        <div class="content">
            <p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Sharan_Neuro-Symbolic_Evaluation_of_Text-to-Video_Models_using_Formal_Verification_CVPR_2025_paper.pdf"><img src="https://img.shields.io/badge/Paper-PDF-green.svg" alt="Paper"></a> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/2411.16718"><img src="https://img.shields.io/badge/arXiv-2403.11021-b31b1b.svg" alt="arXiv"></a> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://utaustin-swarmlab.github.io/NeuS-V/"><img src="https://img.shields.io/badge/ProjectWebpage-NeuS--V-orange.svg" alt="Website"></a> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/UTAustin-SwarmLab/NeuS-V"><img src="https://img.shields.io/badge/Code-NeuS--V-blue.svg" alt="GitHub"></a> <a target="_blank" rel="external nofollow noopener noreferrer" href="https://huggingface.co/spaces/Syzygianinfern0/NeuS-V"><img src="https://img.shields.io/badge/HuggingFace-NeuS--V-yellow.svg" alt="GitHub"></a><br><strong>Minkyu Choi</strong>*, S P Sharan*, Sahil Shah, Harsh Goel, Mohammad Omama, and Sandeep Chinchali<br><em>Computer Vision and Pattern Recognition (CVPR), 2025</em></p>
<span id="more"></span>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In recent years, generative models that create videos from text prompts—known as text-to-video (T2V) models—have advanced significantly. Models like Sora, Gen-3, MovieGen, and CogVideoX are now being used in diverse fields ranging from entertainment to critical applications like autonomous driving and robotics. However, while visually impressive, these models often struggle with accurately capturing temporal sequences described by their prompts.</p>
<h2 id="Why-Temporal-Fidelity-Matters"><a href="#Why-Temporal-Fidelity-Matters" class="headerlink" title="Why Temporal Fidelity Matters"></a>Why Temporal Fidelity Matters</h2><p>For many applications, especially those involving safety-critical tasks, temporal fidelity—the correct timing and sequencing of events—is as important as visual realism. Imagine retraining an autonomous vehicle’s motion planning system using synthetic videos generated from a prompt like, “A truck appears in frame 10 and veers in front of me onto my lane within 2 seconds.” If the timing and sequence of the truck’s movements aren’t accurately represented, it could lead to dangerous decisions in real-world scenarios.</p>
<h2 id="Unveiling-NeuS-V-Neuro-Symbolic-Verification"><a href="#Unveiling-NeuS-V-Neuro-Symbolic-Verification" class="headerlink" title="Unveiling NeuS-V: Neuro-Symbolic Verification"></a>Unveiling NeuS-V: Neuro-Symbolic Verification</h2><br>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="teaser.png" alt title="Figure 1" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
  <em><strong>Fig. 1 Current generative video evaluation methods struggle with temporal fidelity.</strong> <span style="font-style: normal;">NeuS-V</span> converts prompts into Temporal Logic specifications and formally verifies them against a video automaton. The upper video aligns with the prompt's temporal sequencing, while the lower video, despite being visually appealing, fails to do so. Unlike VBench, <span style="font-style: normal;">NeuS-V</span> effectively differentiates between them </em>
  </span>
</div>
<br>

<p>To address the limitations of existing evaluation methods, we introduce NeuS-V, a groundbreaking evaluation technique that employs neuro-symbolic formal verification. NeuS-V translates natural language prompts into formal Temporal Logic (TL) specifications and generates an automaton representing the video’s events and sequences. By formally verifying this automaton against the TL specification, NeuS-V rigorously evaluates text-to-video alignment, significantly outperforming existing metrics.</p>
<h2 id="How-NeuS-V-Works"><a href="#How-NeuS-V-Works" class="headerlink" title="How NeuS-V Works"></a>How NeuS-V Works</h2><p>NeuS-V operates through several key steps:</p>
<ul>
<li><strong>Prompt Translation:</strong> Text prompts are converted into Temporal Logic specifications using Prompt Understanding via temporal Logic Specification (PULS).</li>
<li><strong>Semantic Scoring:</strong> Vision-language models assign confidence scores to each atomic proposition extracted from the prompt.</li>
<li><strong>Automaton Construction:</strong> Videos are represented as automata, capturing the sequential and probabilistic nature of frame-to-frame transitions.</li>
<li><strong>Formal Verification:</strong> Using probabilistic model checking, NeuS-V computes the satisfaction probability of the automaton meeting the prompt’s TL specification.</li>
</ul>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="flowchart.png" alt title="Figure 2" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
  <em><strong>Fig. 2 Spatio-temporal and semantic measurements between a text prompt and a video by <span style="font-style: normal;">NeuS-V</span>.</strong>  We first decompose the text prompt to TL specification $\Phi$, then transform the synthetic video into an automaton representation $\mathcal{A}_{\mathcal{V}}$. Finally, we calculate the satisfaction probability by probabilistically checking the extent to which $\mathcal{A}_{\mathcal{V}}$ satisfies $\Phi$.</em>
  </span>
</div>
<br>

<h2 id="Superior-Evaluation-Results"><a href="#Superior-Evaluation-Results" class="headerlink" title="Superior Evaluation Results"></a>Superior Evaluation Results</h2><p>NeuS-V’s formal approach has shown over five times greater correlation with human evaluations compared to traditional visual quality metrics such as VBench. This indicates NeuS-V’s strength in capturing temporal fidelity, making it particularly effective for scenarios where timing and sequence accuracy are critical.</p>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="correlation.png" alt title="Figure 3" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
  <em><strong>Fig. 3 Correlation with Human Annotations.</strong> <span style="font-style: normal;">NeuS-V</span> consistently shows a stronger alignment with human text-to-video annotations (Pearson coefficients displayed at the top of each plot).</em>
  </span>
</div>
<br>

<h2 id="Benchmark-and-Dataset-Contributions"><a href="#Benchmark-and-Dataset-Contributions" class="headerlink" title="Benchmark and Dataset Contributions"></a>Benchmark and Dataset Contributions</h2><p>To further the development of reliable T2V models, NeuS-V includes a comprehensive benchmark suite with temporally complex prompts designed to rigorously test temporal coherence and event sequencing. These benchmarks, along with the NeuS-V framework and dataset, are publicly available to facilitate continued advancements in the field.</p>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 90%; max-height: 70%; height: auto;">
    <img src="performance_table.png" alt title="Table 1" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 90%; text-align: left; display: block; margin-top: 10px;">
  <em><strong>Tab. 1 Benchmarking SOTA Text-to-Video Models.</strong> Performance metrics reflect the full 360-prompt set, while correlations to human evaluations (in parentheses) are computed on a 160-prompt subset. <span style="font-style: normal;">NeuS-V</span> enjoys high correlation across all themes and complexities.</em>
  </span>
</div>
<br>

<h2 id="Conclusion-and-Future-Directions"><a href="#Conclusion-and-Future-Directions" class="headerlink" title="Conclusion and Future Directions"></a>Conclusion and Future Directions</h2><p>NeuS-V’s integration of neuro-symbolic verification and Temporal Logic addresses a crucial gap in text-to-video generation evaluation. It opens a path toward more reliable generative models, particularly in domains where precise temporal alignment is paramount. Future directions involve refining the NeuS-V framework to penalize unintended elements in generated videos and further exploring prompt optimization and model training methodologies.</p>
<h2 id="Citation"><a href="#Citation" class="headerlink" title="Citation"></a>Citation</h2><figure class="highlight plaintext hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@InProceedings&#123;Choi_2025_CVPR,</span><br><span class="line">    author    = &#123;Sharan, S P and Choi, Minkyu and Shah, Sahil and Goel, Harsh and Omama, Mohammad and Chinchali, Sandeep&#125;,</span><br><span class="line">    title     = &#123;Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification&#125;,</span><br><span class="line">    booktitle = &#123;Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)&#125;,</span><br><span class="line">    month     = &#123;June&#125;,</span><br><span class="line">    year      = &#123;2025&#125;,</span><br><span class="line">    pages     = &#123;8395-8405&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


        </div>
        
        <div class="level is-size-7 is-uppercase post-tags">
            <div class="level-start">
                <div class="tags">
                    <span class="is-size-6 has-text-grey has-mr-7 tag-icon"><i class="fas fa-tag"></i></span>
                    <a class="tag -link-link" href="/tags/artificial-intelligence/" rel="tag">Artificial Intelligence</a><a class="tag -link-link" href="/tags/computer-vision/" rel="tag">Computer Vision</a><a class="tag -link-link" href="/tags/formal-method/" rel="tag">Formal Method</a><a class="tag -link-link" href="/tags/neuro-symbolic-ai/" rel="tag">Neuro-symbolic AI</a>
                </div>
            </div>
        </div>
        
        
        
        
<div class="sharethis-inline-share-buttons"></div>
<script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5d0a1a560345900012ec77c4&amp;product=inline-share-buttons" async="async"></script>

        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-item card to-home">
            <a data-link-name="pagenator" class="level level-item has-link-grey" href="/">
                <i class="fas fa-home"></i> Home
            </a>
        </div>
        
        <div class="level-end card">
            <a data-link-name="pagenator" class="level level-item has-link-grey  article-nav-next" href="/2024/12/01/peernet/">
                PEERNet: Benchmarking Networked Robotics on Wifi, 5G, and Beyond <i class="fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right is-sticky">
    
        
<div class="card widget" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Catalogue
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#Introduction">
        <span class="has-mr-6">1</span>
        <span>Introduction</span>
        </a></li><li>
        <a class="is-flex" href="#Why-Temporal-Fidelity-Matters">
        <span class="has-mr-6">2</span>
        <span>Why Temporal Fidelity Matters</span>
        </a></li><li>
        <a class="is-flex" href="#Unveiling-NeuS-V-Neuro-Symbolic-Verification">
        <span class="has-mr-6">3</span>
        <span>Unveiling NeuS-V: Neuro-Symbolic Verification</span>
        </a></li><li>
        <a class="is-flex" href="#How-NeuS-V-Works">
        <span class="has-mr-6">4</span>
        <span>How NeuS-V Works</span>
        </a></li><li>
        <a class="is-flex" href="#Superior-Evaluation-Results">
        <span class="has-mr-6">5</span>
        <span>Superior Evaluation Results</span>
        </a></li><li>
        <a class="is-flex" href="#Benchmark-and-Dataset-Contributions">
        <span class="has-mr-6">6</span>
        <span>Benchmark and Dataset Contributions</span>
        </a></li><li>
        <a class="is-flex" href="#Conclusion-and-Future-Directions">
        <span class="has-mr-6">7</span>
        <span>Conclusion and Future Directions</span>
        </a></li><li>
        <a class="is-flex" href="#Citation">
        <span class="has-mr-6">8</span>
        <span>Citation</span>
        </a></li></ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/1-research/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">1. Research</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/2-project/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">2. Project</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/3-blog-post/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">3. Blog Post</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">15</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/img/logo.png" alt="Neuro-Symbolic Evaluation of Text-to-Video Models using Formal Verification" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2025 Minkyu Choi&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Google Scholar" href="https://scholar.google.com/citations?user=ai4daB8AAAAJ&amp;hl=en" rel="external nofollow noopener noreferrer">
                        
                        <i class="fas fa-graduation-cap"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="LinkedIn" href="https://www.linkedin.com/in/mchoi07/" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-linkedin"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="GitHub" href="https://github.com/minkyu-choi07" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>

<script>console.log("env -> development");</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="external nofollow noopener noreferrer" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    

    
    
    
    

    
    
    


<script src="/js/main.js" defer></script>
<script src="/js/gaevents.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</body>
</html>