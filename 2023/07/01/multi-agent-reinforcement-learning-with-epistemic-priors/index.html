<!DOCTYPE html>
<html lang="en">
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
<title>Multi-Agent Reinforcement Learning with Epistemic Priors - Minkyu Choi&#39;s Personal Webpage</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="canonical" href="https://minkyuchoi-07.github.io/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/">


    <meta name="description" content="Thayne T. Walker, Jaime S. Ide, Minkyu Choi, Michael John Guarino, and Kevin Alcedo.International Conference on Control, Decision and Information Technologies (CoDit), 2023 The coordination of multipl">
<meta property="og:type" content="article">
<meta property="og:title" content="Multi-Agent Reinforcement Learning with Epistemic Priors">
<meta property="og:url" content="https://minkyuchoi-07.github.io/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/index.html">
<meta property="og:site_name" content="Minkyu Choi&#39;s Personal Webpage">
<meta property="og:description" content="Thayne T. Walker, Jaime S. Ide, Minkyu Choi, Michael John Guarino, and Kevin Alcedo.International Conference on Control, Decision and Information Technologies (CoDit), 2023 The coordination of multipl">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://minkyuchoi-07.github.io/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/thumbnail.png">
<meta property="article:published_time" content="2023-07-01T04:00:00.000Z">
<meta property="article:modified_time" content="2024-11-29T18:14:46.457Z">
<meta property="article:author" content="Minkyu Choi">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Reinforcement Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://minkyuchoi-07.github.io/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/thumbnail.png">




    <meta name="naver-site-verification" content="48beb5f578053c0c5f127b4198a57270bad360ca">


<link rel="canonical" href="https://minkyuchoi-07.github.io/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/">


<link rel="alternative" href="/feed.xml" title="Multi-Agent Reinforcement Learning with Epistemic Priors" type="application/xml">



<link rel="icon" href="/img/favicon.png">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    

    
    
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SNX6P4Y3TY"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-SNX6P4Y3TY');
</script>


    
    
    
    

    
    
    


<link rel="stylesheet" href="/css/style.css">


<script async src="https://www.googletagmanager.com/gtag/js?id=G-SNX6P4Y3TY"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-SNX6P4Y3TY');
</script>

    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9731816337848054", 
    enable_page_level_ads: true
  });
</script>

<meta name="generator" content="Hexo 5.4.2"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>
<body class="is-2-column">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/" data-link-name="navigatorLogo">
            
                <img src="/img/logo.png" alt="Multi-Agent Reinforcement Learning with Epistemic Priors" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a data-link-name="navigator" class="navbar-item" href="/">Home</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/1-research">Research</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/2-project">Project</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/categories/3-blog-post">Blog</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/tags">Tags</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/cv">CV</a>
                
                <a data-link-name="navigator" class="navbar-item" href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="GitHub" href="https://github.com/minkyu-choi07" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-10-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-image">
        <span class="image is-7by1">
            <img class="thumbnail" src="/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/thumbnail.png" alt="Multi-Agent Reinforcement Learning with Epistemic Priors">
        </span>
    </div>
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2023-07-01T04:00:00.000Z">2023-07-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/1-research/">1. Research</a>
                </div>
                
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-bold">
            
                Multi-Agent Reinforcement Learning with Epistemic Priors
            
        </h1>
        
        <hr>
        
        <div class="content">
            <p><a target="_blank" rel="external nofollow noopener noreferrer" href="https://openreview.net/pdf?id=5cWF3p2jDi"><img src="https://img.shields.io/badge/Paper-PDF-green.svg" alt="Paper"></a><br>Thayne T. Walker, Jaime S. Ide, <strong>Minkyu Choi</strong>, Michael John Guarino, and Kevin Alcedo.<br><em>International Conference on Control, Decision and Information Technologies (CoDit), 2023</em></p>
<p>The coordination of multiple autonomous agents is essential for achieving collaborative goals efficiently, especially in environments with limited communication and sensing capabilities. Our recent study, presented at CoDIT 2023, explores a novel method to tackle this challenge. We introduce <strong>Multi-Agent Reinforcement Learning with Epistemic Priors (MARL-EP)</strong>, a technique that leverages shared mental models to enable high-level coordination among agents, even with severely impaired sensing and zero communication.</p>
<span id="more"></span>

<h2 id="Problem-Definition"><a href="#Problem-Definition" class="headerlink" title="Problem Definition"></a>Problem Definition</h2><p>Imagine a scenario where multiple autonomous agents need to navigate from their respective starting positions to specific goal locations. The challenge intensifies when these agents cannot communicate with each other and have limited sensing capabilities, leading to potential collisions or inefficient goal achievement. This problem is prevalent in various applications, including warehouse logistics, firefighting, surveillance, and transportation.</p>
<h3 id="Motivating-Example"><a href="#Motivating-Example" class="headerlink" title="Motivating Example"></a>Motivating Example</h3><p>Consider a cooperative navigation problem where agents must move from their start states to goal states without colliding with each other or obstacles. Traditional methods rely on accurate state information and communication, but what happens when these are unavailable? Figure 1 in our paper illustrates such a scenario where two agents must navigate to their goals without knowing each other’s real-time positions. If each agent independently chooses the shortest path, they will collide. However, with shared knowledge of each other’s goals and an understanding of common conventions, they can avoid collisions and navigate efficiently.</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Multi-Agent-Reinforcement-Learning"><a href="#Multi-Agent-Reinforcement-Learning" class="headerlink" title="Multi-Agent Reinforcement Learning"></a>Multi-Agent Reinforcement Learning</h3><p>Multi-Agent Reinforcement Learning (MARL) involves training multiple agents to make decisions that maximize a cumulative reward. This is often modeled using Decentralized Partially Observable Markov Decision Processes (DEC-POMDPs). These processes account for the fact that agents have only partial information about the environment and must make decisions based on this limited view. Traditional MARL approaches face significant challenges when communication is restricted or when sensing is limited.</p>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/figure1.png" alt title="Figure 1" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
    <em>Figure 1: <strong> (a) An example instance of a cooperative navigation problem and (b) a solution for the problem instance.</strong></em>
  </span>
</div>
<br>

<h3 id="Epistemic-Logic"><a href="#Epistemic-Logic" class="headerlink" title="Epistemic Logic"></a>Epistemic Logic</h3><p>Epistemic logic deals with reasoning about knowledge and beliefs. It allows agents to estimate the knowledge of other agents and predict their actions based on this estimation. By incorporating epistemic logic into MARL, we enable agents to infer unobservable parts of the environment, thereby making more informed decisions.</p>
<h2 id="Reinforcement-Learning-with-Epistemic-Priors"><a href="#Reinforcement-Learning-with-Epistemic-Priors" class="headerlink" title="Reinforcement Learning with Epistemic Priors"></a>Reinforcement Learning with Epistemic Priors</h2><p>Our approach, MARL-EP, integrates epistemic priors into the decision-making process of each agent. These priors serve as a shared mental model, helping agents infer the unobservable parts of the environment and coordinate their actions.</p>
<h3 id="Convention-of-Operation"><a href="#Convention-of-Operation" class="headerlink" title="Convention of Operation"></a>Convention of Operation</h3><p>A convention of operation is a set of predefined rules or protocols that guide agents’ actions to achieve coordination. For example, in traffic systems, the convention might be to drive on the right side of the road. By following such conventions, agents can predict each other’s actions even without direct communication.</p>
<h3 id="Epistemic-Blueprints"><a href="#Epistemic-Blueprints" class="headerlink" title="Epistemic Blueprints"></a>Epistemic Blueprints</h3><p>In the MARL-EP architecture, each agent uses a deterministic multi-agent planner to generate an epistemic blueprint, a complete multi-agent plan. This blueprint guides the agent’s actions, assuming that all agents have identical plans and follow the same conventions. This method allows agents to coordinate implicitly, leveraging shared knowledge and conventions to achieve their goals.</p>
<h3 id="Multi-Agent-RL-with-Epistemic-Priors"><a href="#Multi-Agent-RL-with-Epistemic-Priors" class="headerlink" title="Multi-Agent RL with Epistemic Priors"></a>Multi-Agent RL with Epistemic Priors</h3><p>We employ the QMIX algorithm, which decomposes the global value function into local value functions for each agent, making the learning process more efficient. In our modified approach, we incorporate epistemic priors into the training process. These priors enhance the agents’ understanding of the global state, improving coordination and overall performance.</p>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/figure2.png" alt title="Figure 2" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
    <em>Figure 2: <strong> MARL-EP System Architecture.</strong></em>
  </span>
</div>
<br>

<h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h4><p>Here’s a simplified version of our algorithm:</p>
<ol>
<li><strong>Initialize</strong> the parameters for the mixing network, agent networks, and hypernetwork.</li>
<li><strong>Estimate epistemic priors</strong> for each agent at the beginning of each episode.</li>
<li><strong>Train agents</strong> using local observations augmented with these epistemic priors.</li>
<li><strong>Update model parameters</strong> iteratively based on the observed rewards and transitions.</li>
</ol>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><p>We validated our approach using the Simple-Spread task in the Multi-agent Particle Environment (MPE). This task involves multiple agents cooperating to reach specific landmarks while avoiding collisions. We tested five different scenarios to evaluate the performance of our method:</p>
<ol>
<li><strong>No sensing (baseline)</strong>: Agents have no access to other agents’ locations.</li>
<li><strong>Limited sensing</strong>: Agents can sense nearby agents.</li>
<li><strong>Perfect sensing</strong>: Agents know the locations of all other agents.</li>
<li><strong>No sensing, with priors (QMIX-EP)</strong>: Similar to baseline but with estimated locations of other agents.</li>
<li><strong>Limited sensing, with priors (QMIX-EP)</strong>: Limited sensing augmented with estimated locations.</li>
</ol>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/figure3.png" alt title="Figure 3" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
    <em>Figure 3: <strong>MPE: Simple-spread task. Three agents cooperate to reach the three landmarks as quick as possible, while avoiding collisions. </strong></em>
  </span>
</div>
<br>

<h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>The results, depicted in Figure 4 of our paper, show significant improvements in performance with the use of epistemic priors. In scenarios with no or limited sensing, MARL-EP achieved performance levels close to those with perfect sensing. This demonstrates the effectiveness of using epistemic priors for enhancing coordination among agents.</p>
<div style="text-align: center; display: flex; justify-content: center; align-items: center; min-height: 20vh; flex-direction: column;">
  <span style="max-width: 70%; max-height: 70%; height: auto;">
    <img src="/2023/07/01/multi-agent-reinforcement-learning-with-epistemic-priors/figure4.png" alt title="Figure 4" style="width: 100%; height: auto;">
  </span>
  <span style="max-width: 70%; text-align: left; display: block; margin-top: 10px;">
    <em>Figure 4: <strong>Evaluation of trained QMIX agents for different cases. </strong></em>
  </span>
</div>
<br>

<h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>Our study demonstrates that integrating epistemic priors into multi-agent reinforcement learning can significantly enhance coordination in environments with limited sensing and communication. By leveraging shared mental models and conventions of operation, agents can infer the actions of others and achieve high levels of coordination without direct communication.</p>
<p>Future work will focus on applying this approach in real-world scenarios and exploring real-time updates to the epistemic blueprints. We believe that MARL-EP holds great potential for advancing the capabilities of autonomous multi-agent systems in various applications.</p>
<p>For those interested in the technical details and further results, we encourage you to read our full paper presented at CoDIT 2023.</p>
<h2 id="Citation"><a href="#Citation" class="headerlink" title="Citation"></a>Citation</h2><figure class="highlight plaintext hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@inproceedings&#123;</span><br><span class="line">walker2023multiagent,</span><br><span class="line">title=&#123;Multi-Agent Reinforcement Learning with Epistemic Priors&#125;,</span><br><span class="line">author=&#123;Thayne T. Walker and Jaime S. Ide and Minkyu Choi and Michael John Guarino and Kevin Alcedo&#125;,</span><br><span class="line">booktitle=&#123;PRL Workshop Series &#123;\textendash&#125; Bridging the Gap Between AI Planning and Reinforcement Learning&#125;,</span><br><span class="line">year=&#123;2023&#125;,</span><br><span class="line">url=&#123;https://openreview.net/forum?id=5cWF3p2jDi&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
        </div>
        
        <div class="level is-size-7 is-uppercase post-tags">
            <div class="level-start">
                <div class="tags">
                    <span class="is-size-6 has-text-grey has-mr-7 tag-icon"><i class="fas fa-tag"></i></span>
                    <a class="tag -link-link" href="/tags/artificial-intelligence/" rel="tag">Artificial Intelligence</a><a class="tag -link-link" href="/tags/reinforcement-learning/" rel="tag">Reinforcement Learning</a>
                </div>
            </div>
        </div>
        
        
        
        
<div class="sharethis-inline-share-buttons"></div>
<script type="text/javascript" src="https://platform-api.sharethis.com/js/sharethis.js#property=5d0a1a560345900012ec77c4&amp;product=inline-share-buttons" async="async"></script>

        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start card">
            <a data-link-name="pagenator" class="level level-item has-link-grey article-nav-prev" href="/2023/08/18/distill-neuro-symbolic-ai/">
                <i class="fas fa-chevron-left"></i> Distill Neuro-Symbolic AI
            </a>
        </div>
        
        <div class="with-prev card to-home">
            <a data-link-name="pagenator" class="level level-item has-link-grey" href="/">
                <i class="fas fa-home"></i> Home
            </a>
        </div>
        
        <div class="level-end card">
            <a data-link-name="pagenator" class="level level-item has-link-grey  article-nav-next" href="/2023/04/02/distill-rl/">
                Distill Reinforcement Learning <i class="fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>


</div>
                
                




<div class="column is-4-tablet is-4-desktop is-4-widescreen  has-order-3 column-right is-sticky">
    
        
<div class="card widget" id="toc">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Catalogue
            </h3>
            <ul class="menu-list"><li>
        <a class="is-flex" href="#Problem-Definition">
        <span class="has-mr-6">1</span>
        <span>Problem Definition</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Motivating-Example">
        <span class="has-mr-6">1.1</span>
        <span>Motivating Example</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Background">
        <span class="has-mr-6">2</span>
        <span>Background</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Multi-Agent-Reinforcement-Learning">
        <span class="has-mr-6">2.1</span>
        <span>Multi-Agent Reinforcement Learning</span>
        </a></li><li>
        <a class="is-flex" href="#Epistemic-Logic">
        <span class="has-mr-6">2.2</span>
        <span>Epistemic Logic</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Reinforcement-Learning-with-Epistemic-Priors">
        <span class="has-mr-6">3</span>
        <span>Reinforcement Learning with Epistemic Priors</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Convention-of-Operation">
        <span class="has-mr-6">3.1</span>
        <span>Convention of Operation</span>
        </a></li><li>
        <a class="is-flex" href="#Epistemic-Blueprints">
        <span class="has-mr-6">3.2</span>
        <span>Epistemic Blueprints</span>
        </a></li><li>
        <a class="is-flex" href="#Multi-Agent-RL-with-Epistemic-Priors">
        <span class="has-mr-6">3.3</span>
        <span>Multi-Agent RL with Epistemic Priors</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Algorithm">
        <span class="has-mr-6">3.3.1</span>
        <span>Algorithm</span>
        </a></li></ul></li></ul></li><li>
        <a class="is-flex" href="#Experimental-Results">
        <span class="has-mr-6">4</span>
        <span>Experimental Results</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Results">
        <span class="has-mr-6">4.1</span>
        <span>Results</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Conclusions">
        <span class="has-mr-6">5</span>
        <span>Conclusions</span>
        </a></li><li>
        <a class="is-flex" href="#Citation">
        <span class="has-mr-6">6</span>
        <span>Citation</span>
        </a></li></ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/1-research/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">1. Research</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/2-project/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">2. Project</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/3-blog-post/" data-link-name="category">
            <span class="level-start">
                <span class="level-item">3. Blog Post</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">15</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/img/logo.png" alt="Multi-Agent Reinforcement Learning with Epistemic Priors" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2025 Minkyu Choi&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> & <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Google Scholar" href="https://scholar.google.com/citations?user=ai4daB8AAAAJ&amp;hl=en" rel="external nofollow noopener noreferrer">
                        
                        <i class="fas fa-graduation-cap"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="LinkedIn" href="https://www.linkedin.com/in/mchoi07/" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-linkedin"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="GitHub" href="https://github.com/minkyu-choi07" rel="external nofollow noopener noreferrer">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>

<script>console.log("env -> development");</script>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="external nofollow noopener noreferrer" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    
    
    
    
    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>
    <script src="/js/clipboard.js" defer></script>
    

    
    

    
    
    
    

    
    
    


<script src="/js/main.js" defer></script>
<script src="/js/gaevents.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something...">
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
</body>
</html>